{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tqdm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-0774c81ed76c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;31m# Keras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m \u001b[1;31m# Numpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m \u001b[1;31m# Easy to use function to split my data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m \u001b[1;31m# Library for Visualization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tqdm'"
     ]
    }
   ],
   "source": [
    "import torch # PyTorch\n",
    "import tensorflow as tf # TensorFlow\n",
    "from tensorflow import keras # Keras\n",
    "import numpy as np # Numpy\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split # Easy to use function to split my data\n",
    "import matplotlib.pyplot as plt # Library for Visualization\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "import datetime as dt\n",
    "import pandas_datareader as web\n",
    "\n",
    "#import data\n",
    "data_origin = pd.read_csv(\"Apple5YrData.csv\", sep=\",\")\n",
    "data = data_origin.copy()\n",
    "data['Close/Last'] = data['Close/Last'].str.replace('$', '')\n",
    "data['Open'] = data['Open'].str.replace('$', '')\n",
    "data['High'] = data['High'].str.replace('$', '')\n",
    "data['Low'] = data['Low'].str.replace('$', '')\n",
    "data['Close/Last'] = data['Close/Last'].astype('float')\n",
    "data['Open'] = data['Open'].astype('float')\n",
    "data['High'] = data['High'].astype('float')\n",
    "data['Low'] = data['Low'].astype('float')\n",
    "\n",
    "#get close data\n",
    "noCloseData = np.array(data.drop(['Close/Last', 'Date'], 1))\n",
    "closeData = np.array(data['Close/Last'])\n",
    "closeData = np.flipud(closeData)\n",
    "predictionDays = [60,120,365]\n",
    "predictPrice = [closeData[predictionDays]]\n",
    "\n",
    "\n",
    "#normalize data\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "normalizedData = np.reshape(closeData,(-1,1))\n",
    "\n",
    "#split into test and training data\n",
    "\n",
    "normalizedTrain, normalizedTest = normalizedData[:838,:], normalizedData[838:,:]\n",
    "\n",
    "#set training data\n",
    "def getTrainingData(data,predictionDays):\n",
    "    xTrain = []\n",
    "    yTrain = []\n",
    "    for x in range(predictionDays, len(data)):\n",
    "        xTrain.append(data[x-predictionDays:x,0])\n",
    "        yTrain.append(data[x,0])\n",
    "    xTrain, yTrain = np.array(xTrain), np.array(yTrain)  \n",
    "    xTrain = np.reshape(xTrain,(xTrain.shape[0],xTrain.shape[1],1))\n",
    "    return xTrain, yTrain\n",
    "xTrain60Days, yTrain60Days = getTrainingData(normalizedTrain,predictionDays[0])\n",
    "xTrain120Days, yTrain120Days = getTrainingData(normalizedTrain,predictionDays[1])\n",
    "xTrain365Days, yTrain365Days = getTrainingData(normalizedTrain,predictionDays[2])\n",
    "\n",
    "xTest60Days, yTest60Days = getTrainingData(normalizedTest,predictionDays[0])\n",
    "print(xTrain60Days.shape[1])\n",
    "LSTMmodel = Sequential()\n",
    "\n",
    "LSTMmodel.add(LSTM(units = 50,return_sequences = True, input_shape=(xTrain60Days.shape[1],1)))\n",
    "LSTMmodel.add(Dropout(0.2))\n",
    "LSTMmodel.add(LSTM(units = 50,return_sequences = True))\n",
    "LSTMmodel.add(Dropout(0.2))\n",
    "LSTMmodel.add(LSTM(units = 50))\n",
    "LSTMmodel.add(Dropout(0.2))\n",
    "LSTMmodel.add(Dense(units=1))\n",
    "\n",
    "LSTMmodel.compile(optimizer='adam', loss='mean_squared_error')\n",
    "LSTMmodel.fit(xTrain60Days, xTrain60Days, epochs=15, batch_size=32)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_inputs = normalizedTest \n",
    "predictions = []\n",
    "for inputDays in xTest60Days:\n",
    "    predictions.append\n",
    "    \n",
    "output = LSTMmodel.predict(xTest60Days) \n",
    "print(output)\n",
    "xTest = []\n",
    "#for x in range(predictionDays[0], len(xTest60Days)):\n",
    "    #xTest.append(LSTMmodel.predict(xTest60Days[x]))\n",
    "#xTest = np.array(xTest)\n",
    "#plot\n",
    "plt.plot(normalizedTest, color=\"black\", label=f\"Actual Price\")\n",
    "plt.plot(predictPrice, color=\"red\", label=f\"Predicted Price\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
