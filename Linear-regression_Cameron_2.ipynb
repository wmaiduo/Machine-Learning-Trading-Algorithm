{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b83eb994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "25/25 [==============================] - 1s 2ms/step - loss: 0.3070\n",
      "Epoch 2/15\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0390\n",
      "Epoch 3/15\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 4/15\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0120\n",
      "Epoch 5/15\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0113\n",
      "Epoch 6/15\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0110\n",
      "Epoch 7/15\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0109\n",
      "Epoch 8/15\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0102\n",
      "Epoch 9/15\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0107\n",
      "Epoch 10/15\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0106\n",
      "Epoch 11/15\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0107\n",
      "Epoch 12/15\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0107\n",
      "Epoch 13/15\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0103\n",
      "Epoch 14/15\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0099\n",
      "Epoch 15/15\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0111\n",
      "[[[0.11864035]\n",
      "  [0.12143858]\n",
      "  [0.11726621]\n",
      "  ...\n",
      "  [0.12376213]\n",
      "  [0.12671028]\n",
      "  [0.13090765]]\n",
      "\n",
      " [[0.12143858]\n",
      "  [0.11726621]\n",
      "  [0.11706634]\n",
      "  ...\n",
      "  [0.12671028]\n",
      "  [0.13090765]\n",
      "  [0.13045792]]\n",
      "\n",
      " [[0.11726621]\n",
      "  [0.11706634]\n",
      "  [0.11796577]\n",
      "  ...\n",
      "  [0.13090765]\n",
      "  [0.13045792]\n",
      "  [0.11993952]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.77082527]\n",
      "  [0.81158894]\n",
      "  [0.81112117]\n",
      "  ...\n",
      "  [0.7661809 ]\n",
      "  [0.75879663]\n",
      "  [0.77202815]]\n",
      "\n",
      " [[0.81158894]\n",
      "  [0.81112117]\n",
      "  [0.81706864]\n",
      "  ...\n",
      "  [0.75879663]\n",
      "  [0.77202815]\n",
      "  [0.7658133 ]]\n",
      "\n",
      " [[0.81112117]\n",
      "  [0.81706864]\n",
      "  [0.8034028 ]\n",
      "  ...\n",
      "  [0.77202815]\n",
      "  [0.7658133 ]\n",
      "  [0.78559375]]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. Estimator expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-a10b551aff34>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLSTMmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestData\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m \u001b[0moutput\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[0mActualPrice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcloseData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormalizedData\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtrainingToTestRation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36minverse_transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    456\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m         X = check_array(X, copy=self.copy, dtype=FLOAT_DTYPES,\n\u001b[0m\u001b[0;32m    459\u001b[0m                         force_all_finite=\"allow-nan\")\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    657\u001b[0m                     \"into decimal numbers with dtype='numeric'\") from e\n\u001b[0;32m    658\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 659\u001b[1;33m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n\u001b[0m\u001b[0;32m    660\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with dim 3. Estimator expected <= 2."
     ]
    }
   ],
   "source": [
    "import torch # PyTorch\n",
    "import tensorflow as tf # TensorFlow\n",
    "from tensorflow import keras # Keras\n",
    "import numpy as np # Numpy\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split # Easy to use function to split my data\n",
    "import matplotlib.pyplot as plt # Library for Visualization\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "#import data\n",
    "data_origin = pd.read_csv(\"Apple5YrData.csv\", sep=\",\")\n",
    "data = data_origin.copy()\n",
    "data['Close/Last'] = data['Close/Last']\n",
    "data['Close/Last'] = data['Close/Last'].astype('float')\n",
    "data['Open'] = data['Open'].astype('float')\n",
    "data['High'] = data['High'].astype('float')\n",
    "data['Low'] = data['Low'].astype('float')\n",
    "\n",
    "#get close data\n",
    "noCloseData = np.array(data.drop(['Close/Last', 'Date'], 1))\n",
    "closeData = np.array(data['Close/Last'])\n",
    "predictionDays = 60\n",
    "\n",
    "predictPrice = [closeData[predictionDays]]\n",
    "\n",
    "\n",
    "#normalize data\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "normalizedData = closeData\n",
    "\n",
    "#split into test and training data\n",
    "trainingToTestRation = .66\n",
    "trainDataset,testDataset = normalizedData[:int(len(normalizedData)*trainingToTestRation)], normalizedData[int(len(normalizedData)*trainingToTestRation):]\n",
    "\n",
    "normalizedTrain = scaler.fit_transform(np.reshape(trainDataset,(-1,1)))\n",
    "\n",
    "#set training data\n",
    "def getTrainingData(data,predictionDays):\n",
    "    xTrain = []\n",
    "    yTrain = []\n",
    "    for x in range(predictionDays, len(data)):\n",
    "        xTrain.append(data[x-predictionDays:x,0])\n",
    "        yTrain.append(data[x,0])\n",
    "    xTrain, yTrain = np.array(xTrain), np.array(yTrain)  \n",
    "    xTrain = np.reshape(xTrain,(xTrain.shape[0],xTrain.shape[1],1))\n",
    "    return xTrain, yTrain\n",
    "\n",
    "xTrain, yTrain = getTrainingData(normalizedTrain,predictionDays)\n",
    "\n",
    "\n",
    "#LSTM MOdel\n",
    "LSTMmodel = keras.Sequential([\n",
    "    keras.layers.Dense(32, activation=tf.nn.relu,input_shape=(xTrain.shape[1],1)),\n",
    "    keras.layers.Dense(32, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(32, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(units=1)\n",
    "  ])\n",
    "LSTMmodel.compile(optimizer='adam', loss='mean_squared_error')\n",
    "LSTMmodel.fit(xTrain, yTrain, epochs=15, batch_size=32)\n",
    "\n",
    "#get input test data\n",
    "def getTestData(data,predictionDays,trainingToTestRation):\n",
    "    xTest = []\n",
    "    totalDataset = np.concatenate((trainDataset,testDataset),axis = 0)\n",
    "    testInputs = data[(len(totalDataset) - len(testDataset) - predictionDays):]\n",
    "    testInputs = testInputs.reshape(-1,1)\n",
    "    testInputs = scaler.fit_transform(testInputs)\n",
    "    count = 0\n",
    "    for x in range(predictionDays, len(testInputs)):\n",
    "        xTest.append(testInputs[x-predictionDays:x,0])\n",
    "        count += 1\n",
    "    xTest = np.array(xTest)\n",
    "    xTest = np.reshape(xTest, (xTest.shape[0],xTest.shape[1],1) )\n",
    "    return xTest \n",
    "testData = getTestData(closeData,predictionDays,trainingToTestRation)\n",
    "\n",
    "#put through model and get predictions\n",
    "output = LSTMmodel.predict(testData)\n",
    "print(output)\n",
    "output  = scaler.inverse_transform(output)\n",
    "print(output)\n",
    "ActualPrice = closeData[int(len(normalizedData)*trainingToTestRation):]\n",
    "\n",
    "#plot predictions\n",
    "plt.plot(ActualPrice , color=\"black\", label=f\"Actual Price\")\n",
    "plt.plot(output, color=\"red\", label=f\"Predicted Price\")\n",
    "plt.xlabel(\"Days\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "shares = 10000/ActualPrice[0]\n",
    "cash = 0\n",
    "\n",
    "print('predictionDays: ', predictionDays, ActualPrice[predictionDays + 1])\n",
    "\n",
    "netInCash = []\n",
    "notMoved = []\n",
    "noMshare = 10000/ActualPrice[0]\n",
    "print(len(output))\n",
    "for i in range(len(output)-1):\n",
    "    if output[i+1] > ActualPrice[i]:\n",
    "        if cash > 0:\n",
    "            shares = cash / ActualPrice[i]\n",
    "            cash = 0\n",
    "    if output[i+1] < ActualPrice[i]:\n",
    "        if shares > 0:\n",
    "            cash = shares * ActualPrice[i]\n",
    "            shares = 0\n",
    "    if shares > 0:\n",
    "        netInCash.append(shares*ActualPrice[i])\n",
    "    else:\n",
    "        netInCash.append(cash)\n",
    "    notMoved.append(noMshare*ActualPrice[i])\n",
    "\n",
    "    \n",
    "differenceInPredictions = 0\n",
    "for i in range(len(output)):\n",
    "    differenceInPredictions += abs(output[i]-ActualPrice[i])\n",
    "    \n",
    "    \n",
    "print(differenceInPredictions)\n",
    "    \n",
    "plt.plot(netInCash, color=\"black\", label=\"Net Cash if trading off predictions\")\n",
    "plt.plot(notMoved, color=\"red\", label=\"Net Cash from NotTrading\")\n",
    "blackPatch = mpatches.Patch(color=\"black\", label=\"LSTM Predictions\")\n",
    "redPatch = mpatches.Patch(color=\"red\", label=\"NotTrading\")\n",
    "plt.legend(handles=[blackPatch, redPatch])\n",
    "plt.ylabel(\"Net Value\")\n",
    "plt.xlabel(\"Days Passed\")\n",
    "plt.title(\"Buying/Selling based off predictions vs \")\n",
    "plt.show()\n",
    "\n",
    "print(\"Total Shares: \", shares*ActualPrice[i])\n",
    "print(\"Total price: \", cash)\n",
    "print(\"Natural: \", noMshare*ActualPrice[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f666a8f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
